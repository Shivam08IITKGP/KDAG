Metadata-Version: 2.4
Name: kdag-backstory-consistency
Version: 0.1.0
Summary: Evidence-Grounded Backstory Consistency System using LangGraph and GraphRAG
Author-email: KDAG Team <kdag@example.com>
Keywords: rag,langgraph,consistency-checking,nlp,knowledge-graph
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Requires-Python: >=3.10
Description-Content-Type: text/markdown
Requires-Dist: pandas
Requires-Dist: python-dotenv
Requires-Dist: langgraph
Requires-Dist: langchain
Requires-Dist: langchain-community
Requires-Dist: langchain-openai
Requires-Dist: langchain-text-splitters
Requires-Dist: networkx
Requires-Dist: qdrant-client
Requires-Dist: sentence-transformers
Requires-Dist: numpy
Requires-Dist: tiktoken
Requires-Dist: httpx
Requires-Dist: langchain-google-genai
Provides-Extra: dev
Requires-Dist: pytest; extra == "dev"
Requires-Dist: black; extra == "dev"
Requires-Dist: ruff; extra == "dev"
Requires-Dist: mypy; extra == "dev"

# KDAG: Knowledge-Graph-Driven Backstory Consistency System

A LangGraph-based agentic pipeline that validates character backstory consistency against source novels using Graph RAG (Retrieval Augmented Generation).

## System Architecture

```mermaid
graph TB
    Start([User Input]) --> Input[Input Module<br/>train.csv]
    Input --> BuildIndex[Build Index<br/>Qdrant Vector DB]
    
    BuildIndex --> Pipeline{LangGraph Pipeline}
    
    Pipeline --> Extract[Extraction Agent<br/>Generate Queries]
    Extract --> Retrieve[Retrieve Evidence<br/>Vector Search + Reranking]
    Retrieve --> GraphCreate[Graph Creator Agent<br/>Build Knowledge Graph]
    GraphCreate --> Answer[Answering Agent<br/>Classify Consistency]
    
    Answer --> Output[Output<br/>output.csv]
    
    style Extract fill:#e1f5ff
    style GraphCreate fill:#fff4e1
    style Answer fill:#e8f5e9
    style BuildIndex fill:#f3e5f5
```

## Pipeline Flow

### 1. **Input Processing** (`input.py`, `main.py`)
- Reads character backstories from `train.csv`
- Each row contains: `book_name`, `char` (character name), `content` (backstory)
- User specifies number of rows to process

### 2. **Index Building** (`Graphrag/pathway/build_index.py`)
- **First-time per book**: Chunks novel text using `RecursiveCharacterTextSplitter`
  - Chunk size: 1000 characters
  - Overlap: 100 characters
- Generates embeddings using `SentenceTransformer` (all-MiniLM-L6-v2)
- Stores in Qdrant vector database as `{book_name}_collection`

### 3. **Extraction Agent** (`extraction_agent/`)
- **Input**: Character name, backstory, book name
- **Process**:
  - Uses LLM to generate search queries (max 5) from backstory
  - Queries extract key claims to verify
- **Output**: List of verification queries

### 4. **Evidence Retrieval** (`Graphrag/pathway/retriever.py`)
- **Two-stage retrieval**:
  1. **Vector Search**: Retrieves top-50 candidates from Qdrant
  2. **Reranking**: CrossEncoder reranks to top-5 most relevant chunks
- Returns evidence with IDs, text, and relevance scores

### 5. **Graph Creator Agent** (`graph_creator_agent/`)
- **Input**: Evidence chunks
- **Process**:
  - Extracts knowledge triplets: `(subject, predicate, object)`
  - Builds/updates NetworkX knowledge graph
  - Caches processed evidence to avoid duplication
- **Output**: GraphML file stored in `graph_creator_agent/graph/`
- **Components**:
  - `extractor.py`: LLM-based triplet extraction
  - `graph_store.py`: Graph persistence (load/save GraphML)
  - `cache.py`: Evidence deduplication cache

### 6. **Answering Agent** (`answering_agent/`)
- **Classifier** (`classifier.py`):
  - Analyzes backstory against knowledge graph
  - Returns: `label` (1=Consistent, 0=Contradicting) + `reasoning`
- **Evidence Generator** (`evidence_generator.py`):
  - Identifies specific evidence IDs supporting the classification
- **Output**: Final verdict with supporting evidence

### 7. **Output Generation** (`main.py`)
- Writes results to `output.csv`:
  - `book_name`, `character_name`, `predictions`, `reasoning`
- Incremental saving (appends after each row)
- Detailed logs in `logs/run_{timestamp}.log`

## Key Technologies

| Component | Technology |
|-----------|-----------|
| **Orchestration** | LangGraph (StateGraph) |
| **LLM** | OpenRouter API |
| **Vector DB** | Qdrant |
| **Embeddings** | SentenceTransformer (all-MiniLM-L6-v2) |
| **Reranking** | CrossEncoder (ms-marco-MiniLM-L-6-v2) |
| **Knowledge Graph** | NetworkX (GraphML format) |
| **Text Splitting** | LangChain RecursiveCharacterTextSplitter |

## Project Structure

```
KDAG/
â”œâ”€â”€ main.py                    # Pipeline orchestrator
â”œâ”€â”€ input.py                   # Data loader
â”œâ”€â”€ shared_config.py           # LLM configuration
â”œâ”€â”€ train.csv                  # Input dataset
â”œâ”€â”€ output.csv                 # Results
â”‚
â”œâ”€â”€ extraction_agent/          # Query generation
â”‚   â”œâ”€â”€ main.py               # Agent entry point
â”‚   â”œâ”€â”€ prompts.py            # LLM prompts
â”‚   â””â”€â”€ config.py             # Agent config
â”‚
â”œâ”€â”€ graph_creator_agent/       # Knowledge graph builder
â”‚   â”œâ”€â”€ main.py               # Agent entry point
â”‚   â”œâ”€â”€ extractor.py          # Triplet extraction
â”‚   â”œâ”€â”€ graph_store.py        # Graph I/O operations
â”‚   â”œâ”€â”€ cache.py              # Evidence caching
â”‚   â”œâ”€â”€ types.py              # Type definitions
â”‚   â””â”€â”€ graph/                # Saved graphs (.graphml)
â”‚
â”œâ”€â”€ answering_agent/           # Classification
â”‚   â”œâ”€â”€ main.py               # Agent entry point
â”‚   â”œâ”€â”€ classifier.py         # Consistency classifier
â”‚   â”œâ”€â”€ evidence_generator.py # Evidence ID extraction
â”‚   â””â”€â”€ prompts.py            # LLM prompts
â”‚
â””â”€â”€ Graphrag/pathway/          # RAG infrastructure
    â”œâ”€â”€ build_index.py        # Vector index builder
    â””â”€â”€ retriever.py          # Hybrid retrieval
```

## Usage

```bash
# 1. Start Qdrant
docker run -p 6333:6333 qdrant/qdrant

# 2. Set environment variables
export OPENROUTER_API_KEY="your_key"
export QDRANT_URL="http://localhost:6333"

# 3. Run pipeline
python main.py
# Enter number of rows to process: 2
```

## State Management

The pipeline uses a `PipelineState` TypedDict that flows through all agents:

```python
{
    "book_name": str,
    "character_name": str,
    "backstory": str,
    "queries": list[str],           # From extraction agent
    "evidences": list[dict],        # From retrieval
    "graph_path": str,              # From graph creator
    "label": int,                   # From answering agent (1/0)
    "reasoning": str,               # From answering agent
    "evidence_ids": list[str]       # From answering agent
}
```

## Logging

- **Location**: `logs/run_{timestamp}.log`
- **Format**: Structured logs with timestamp, level, module, function, line number
- **Levels**: DEBUG (file), INFO (console + file)

---

## Configuration & Index Management

### Index Management Commands

```bash
# List all indexed books
python -m Graphrag.pathway.index_manager --list

# Clear specific book (case-insensitive)
python -m Graphrag.pathway.index_manager --clear "the count of monte cristo"

# Clear all indexes (requires confirmation)
python -m Graphrag.pathway.index_manager --clear-all

# Rebuild specific book with current config
python -m Graphrag.pathway.index_manager --rebuild \
  --path Books/book.txt \
  --name "Book Name"
```

### Configuration File

All parameters are centralized in `Graphrag/config.py`:

```python
# Retrieval
RETRIEVAL_TOP_K = 10         # Final results returned
RETRIEVAL_INITIAL_K = 50     # Candidates for reranking

# Chunking
CHUNK_SIZE = 1000            # Characters per chunk
CHUNK_OVERLAP = 100          # Overlap between chunks

# Models
EMBEDDING_MODEL = "sentence-transformers/all-MiniLM-L6-v2"
RERANKER_MODEL = "cross-encoder/ms-marco-MiniLM-L-6-v2"
```

**To change parameters:**
1. Edit `Graphrag/config.py`
2. Clear affected indexes: `python -m Graphrag.pathway.index_manager --clear-all`
3. Re-run `main.py` to rebuild with new settings

### Indexing Behavior

**First run per book:**
- Chunks text, embeds, stores in Qdrant collection `{book_name}_collection`

**Subsequent runs:**
- Reuses existing Qdrant collection (no rebuild)

**Force rebuild:**
- Clear index using `index_manager`, then re-run `main.py`

---

## Issues & Incomplete Functions

### ğŸ”´ Critical Issues

1. **Missing `retrieve` function** (`Graphrag/pathway/retrieve.py`)
   - `main.py:17` imports `retrieve_topk` from `Graphrag.pathway.retrieve`
   - File is named `retriever.py` but import expects `retrieve.py`
   - **Fix**: Rename `retriever.py` â†’ `retrieve.py` OR update import

2. **Hardcoded book paths** (`main.py:189-199`)
   - Only supports 2 books: "In Search of the Castaways" and "The Count of Monte Cristo"
   - New books require code changes
   - **Fix**: Create book registry or dynamic path resolution

3. **Duplicate CSV writing** (`main.py:220-230, 242-258`)
   - Results written twice: incrementally (line 229) and batch (line 256)
   - Causes duplicate entries in `output.csv`
   - **Fix**: Remove batch writing section (lines 242-258)

### âš ï¸ Warnings

4. **No error handling for Qdrant connection**
   - `build_index.py` and `retriever.py` assume Qdrant is running
   - **Fix**: Add connection retry logic and clear error messages

5. **LLM response parsing fragility** (`extraction_agent/main.py:66-87`)
   - Relies on JSON extraction from markdown code blocks
   - Falls back to empty list on parse errors
   - **Fix**: Add structured output validation or use function calling

6. **Cache persistence** (`graph_creator_agent/cache.py`)
   - Evidence cache saved to JSON but no cleanup mechanism
   - Can grow indefinitely
   - **Fix**: Add cache size limits or TTL

7. **Graph merging logic** (`graph_creator_agent/graph_store.py`)
   - No conflict resolution for duplicate triplets
   - **Fix**: Add triplet deduplication before adding to graph

### ğŸ“ Minor Issues

8. **Unused imports** (`answering_agent/main.py:3`)
   - `os` imported but not used

9. **Magic numbers**
   - Retrieval k=5, initial_k=50 hardcoded in `retriever.py`
   - Chunk size/overlap in `build_index.py`
   - **Fix**: Move to config files

10. **No input validation**
    - `train.csv` format not validated
    - Missing columns would cause runtime errors
    - **Fix**: Add schema validation

### âœ… Recommendations

- Add unit tests for each agent
- Implement retry logic for LLM calls
- Add progress bars for batch processing
- Create configuration file (YAML/JSON) for all parameters
- Add graph visualization utilities
- Implement async processing for parallel evidence retrieval
